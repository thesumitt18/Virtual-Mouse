This project is an innovative virtual mouse system that leverages hand gestures to control cursor movement and perform mouse operations, offering a touchless and intuitive user interface. By using a camera to capture real-time video input, the system detects and interprets hand gestures to simulate mouse actions, such as moving the cursor, clicking, and scrolling. This technology can be particularly useful in scenarios where touch-based input is impractical or unhygienic.

Technologies Used
OpenCV: For real-time image processing and hand detection.
Mediapipe: For robust hand tracking and gesture recognition.
Python: The primary programming language for development.
PyAutoGUI: For controlling the mouse and keyboard programmatically.
